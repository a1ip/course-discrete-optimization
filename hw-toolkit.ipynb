{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from subprocess import run, PIPE\n",
    "from os import mkdir, listdir\n",
    "from os.path import isdir, exists\n",
    "\n",
    "import json\n",
    "from itertools import starmap\n",
    "from datetime import datetime\n",
    "\n",
    "from re import sub\n",
    "from collections import namedtuple\n",
    "\n",
    "import lzma\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "def checkNCD(str_dict, threshold, verbose=False):\n",
    "    new_dict = dict()\n",
    "    complen_dict = dict()\n",
    "    pairs = dict()\n",
    "    for i in str_dict:\n",
    "        s = sub(r'\\s+', ' ', str_dict[i].lower()).encode()\n",
    "        new_dict[i] = s\n",
    "        complen_dict[i] = len(lzma.compress(s))\n",
    "\n",
    "    all_pairs = list(combinations(new_dict.items(), 2))\n",
    "    i = 0\n",
    "    one_percent = len(all_pairs) // 100\n",
    "    for (i1, s1), (i2, s2) in all_pairs:\n",
    "        i += 1\n",
    "        l1 = complen_dict[i1]\n",
    "        l2 = complen_dict[i2]\n",
    "        NCDistance = (len(lzma.compress(s1 + s2)) - min(l1, l2)) / max(l1, l2)\n",
    "        if NCDistance <= threshold:\n",
    "            pairs[(i1, i2)] = NCDistance\n",
    "        if verbose and one_percent > 0 and i % one_percent == 0:\n",
    "            print(str(i / one_percent) + '%')\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def extract_function_definition(text, function_name):\n",
    "    result = ''\n",
    "    function_started = False\n",
    "    for line in text.split('\\n'):\n",
    "        if line.startswith('def') and function_name in line:\n",
    "            function_started = True\n",
    "        elif function_started:\n",
    "            if line.startswith(' ') or line.startswith('\\t'):\n",
    "                result += line + '\\n'\n",
    "            else:\n",
    "                break\n",
    "    return result\n",
    "\n",
    "def skip_functions(text, function_names):\n",
    "    result = ''\n",
    "    function_started = False\n",
    "    for line in text.split('\\n'):\n",
    "        if line.startswith('def') and not any(name in line for name in function_names):\n",
    "            function_started = True\n",
    "        elif function_started:\n",
    "            if line.startswith(' ') or line.startswith('\\t'):\n",
    "                result += line + '\\n'\n",
    "            else:\n",
    "                function_started = False\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learners = '''Белых Евгений\t\thttps://github.com/white2302/discrete-optimization-course-homework\n",
    "Васильев Александр\t\thttps://github.com/mizabrik/discrete-optimization-course-homework\n",
    "Герасимов Артём\t\thttps://github.com/gerasartem/discrete-optimization-course-homework\n",
    "Горелик Александр\t\thttps://github.com/alexgorelick/discrete-optimization-course-homework\n",
    "Гришутин Александр\t\thttps://github.com/agrishutin/discrete-optimization-course-homework\n",
    "Гусарова Дарья\t\thttps://github.com/DariaGusarova/discrete-optimization-course-homework\n",
    "Зуева Надежда\t\thttps://github.com/nadezhdazueva/DiscreteOpt\n",
    "Калиниченко Ольга\t\thttps://github.com/madshuttlecock/discrete-optimization-course-homework\n",
    "Куприянов Артем\t\thttps://github.com/ArtemKupriyanov/discrete-optimization-course-homework\n",
    "Литвинов Станислав\t\thttps://github.com/litvinovSA/discrete-optimization-course-homework\n",
    "Марков Александр\t\thttps://github.com/markovalexander/discrete-optimization-course-homework\n",
    "Мартинсон Михаил\t\thttps://github.com/MartinsonMichael/discrete-optimization-course-homework\n",
    "Муравьев Кирилл\t\thttps://github.com/KirillMouraviev/discrete-optimization-course-homework\n",
    "Мурзин Дмитрий\t\thttps://github.com/dima74/discrete-optimization-course-homework\n",
    "Немычникова Валерия\t\thttps://github.com/sooobus/discrete-optimization-course-homework\n",
    "Нифантова Ирина\t\thttps://github.com/NifantovaIrina/discrete-optimization-course-homework\n",
    "Петров Филипп\t\thttps://github.com/yaPhilya/discrete-optimization-course-homework\n",
    "Проскурин Александр\t\thttps://github.com/aleksProsk/discrete-optimization-course-homework\n",
    "Пыркин Дмитрий\t\thttps://github.com/Blacksorld/discrete-optimization-course-homework\n",
    "Лернер Регина\t\thttps://github.com/flagolyub/discrete-optimization-course-homework\n",
    "Рейдман Павел\t\thttps://github.com/preidman/discrete-optimization-course-homework\n",
    "Ремизова Анастасия\t\thttps://github.com/feathernox/discrete-optimization-course-homework\n",
    "Рязановский Данила\t\thttps://github.com/riazanovskiy/discrete-optimization-course-homework\n",
    "Ткаченко Дмитрий\t\thttps://github.com/JerryCh0/discrete-optimization-course-homework\n",
    "Троцюк Владислав\t\thttps://github.com/vladtrotsiuk/discrete-optimization-course-homework\n",
    "Якушева Софья\t\thttps://github.com/stager108/discrete-optimization-course-homework'''\n",
    "\n",
    "Learner = namedtuple( 'Learner', ['lastname', 'firstname', 'github_username'] )\n",
    "\n",
    "learners = list(map(\n",
    "    lambda s: Learner(*s.split()), \n",
    "    sub(r'https://[^/]*/([^/]*)/discrete-optimization-course-homework', r'\\1', learners.replace('\\t\\t',' ')).split('\\n')\n",
    "))\n",
    "\n",
    "main_repo_dir = r'c:\\Users\\daini\\Documents\\disco2017-hw-check'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cloneAllRepos():\n",
    "    global learners\n",
    "    print('Going to process {} user repos.'.format(len(learners)))\n",
    "    \n",
    "    for learner in learners:\n",
    "        repo_local_dirname = main_repo_dir + r'\\{}'.format(learner.lastname)\n",
    "        repo_remote_dirname = 'https://github.com/{}/discrete-optimization-course-homework.git'.format(learner.github_username)\n",
    "        if not isdir(repo_local_dirname):\n",
    "            print('Directory “{}” doesn’t exist. Creating it.'.format(repo_local_dirname))\n",
    "            mkdir(repo_local_dirname)\n",
    "        if listdir(repo_local_dirname) == []:\n",
    "            print('Executing “git clone {} {}”'.format(repo_remote_dirname, repo_local_dirname), end=' ')\n",
    "            git_run_result = run([r'C:\\Users\\daini\\AppData\\Local\\GitHub\\PortableGit_f02737a78695063deace08e96d5042710d3e32db\\cmd\\git.exe', 'clone', repo_remote_dirname, repo_local_dirname], stdout=PIPE, stderr=PIPE)            \n",
    "        else:\n",
    "            print('Repo “{}” already exists; trying to update.'.format(repo_local_dirname), end=' ')\n",
    "            git_run_result = run([r'C:\\Users\\daini\\AppData\\Local\\GitHub\\PortableGit_f02737a78695063deace08e96d5042710d3e32db\\cmd\\git.exe', 'pull', repo_remote_dirname], stdout=PIPE, stderr=PIPE, cwd=repo_local_dirname)\n",
    "        if len(git_run_result.stdout) > 0:\n",
    "                print('\\n', git_run_result.stdout.decode(\"utf-8\", \"backslashreplace\"))\n",
    "        print('done')\n",
    "    print('All repositories updated.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkoutToDate(deadline, verbose = False):\n",
    "    global learners\n",
    "    if not verbose:\n",
    "        print('Doing the checkout…', end='')\n",
    "    for learner in learners:\n",
    "        if verbose:\n",
    "            print('Processing {}'.format(learner.lastname))\n",
    "        repo_local_dirname = main_repo_dir + r'\\{}'.format(learner.lastname)\n",
    "        if not isdir(repo_local_dirname) and verbose:\n",
    "            print('Directory “{}” doesn’t exist. Skipping.'.format(repo_local_dirname))\n",
    "            continue\n",
    "        path = 'git rev-list -n 1 --before=\"{}\" master'.format(deadline)\n",
    "        if verbose:\n",
    "            print('Performing checkout of path “{}”…'.format(path))\n",
    "        git_run_result = run([r'C:\\Users\\daini\\AppData\\Local\\GitHub\\PortableGit_f02737a78695063deace08e96d5042710d3e32db\\cmd\\git.exe', 'checkout', path], stdout=PIPE, stderr=PIPE, cwd=repo_local_dirname)\n",
    "        if len(git_run_result.stdout) > 0 and verbose:\n",
    "            print('\\n', git_run_result.stdout.decode(\"utf-8\", \"backslashreplace\"))\n",
    "        \n",
    "        if verbose:\n",
    "            print('Cleaning the repo…')\n",
    "        git_run_result = run([r'C:\\Users\\daini\\AppData\\Local\\GitHub\\PortableGit_f02737a78695063deace08e96d5042710d3e32db\\cmd\\git.exe', 'clean', '-fdxX'], stdout=PIPE, stderr=PIPE, cwd=repo_local_dirname)\n",
    "        if len(git_run_result.stdout) > 0 and verbose:\n",
    "            print('\\n', git_run_result.stdout.decode(\"utf-8\", \"backslashreplace\"))\n",
    "    if not verbose:\n",
    "        print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cloneAllRepos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_plagiarism_in_function(notebook_name, function_name, threshold=0.5):\n",
    "    all_solutions = defaultdict(lambda: defaultdict(str))\n",
    "    \n",
    "    for learner in learners:\n",
    "        filename = main_repo_dir + r'\\{0}\\{1}'.format(learner.lastname, notebook_name)\n",
    "        if not exists(filename):\n",
    "            continue\n",
    "        with open( filename, 'r', encoding='utf8' ) as nbfile:\n",
    "            nb = json.load( nbfile )\n",
    "            code_cells = []\n",
    "            for cell in nb['cells']:\n",
    "                if cell['cell_type'] != 'code':\n",
    "                    continue\n",
    "                cell_text = sub(r'#.*', '', ''.join(s for s in cell['source'] if not s.startswith('#')))\n",
    "                core_text = extract_function_definition(cell_text, function_name)\n",
    "                if core_text:\n",
    "                    all_solutions[learner.lastname] = core_text\n",
    "\n",
    "    no_duplicates = True\n",
    "\n",
    "    print('Processing…', end='')\n",
    "    similarPairs = checkNCD(all_solutions, threshold)\n",
    "    print('done!')\n",
    "\n",
    "    if len(similarPairs) > 0:\n",
    "        formatted_output = sorted(\n",
    "            (similarPairs[pair], '{2}: ({0}, {1})'.format(pair[0], pair[1], round(similarPairs[pair], 2))) \n",
    "            for pair in similarPairs\n",
    "        )\n",
    "        print('Similar definitions of “{}” in {}:'.format(function_name, notebook_name))\n",
    "        print('\\n'.join(x[1] for x in formatted_output))\n",
    "    else:\n",
    "        print('No duplicates')\n",
    "    return all_solutions\n",
    "\n",
    "def find_plagiarism_in_code(notebook_name, ignored_function_names, threshold=0.5):\n",
    "    all_solutions = defaultdict(lambda: defaultdict(str))\n",
    "    \n",
    "    for learner in learners:\n",
    "        filename = main_repo_dir + r'\\{0}\\{1}'.format(learner.lastname, notebook_name)\n",
    "        if not exists(filename):\n",
    "            continue\n",
    "        with open( filename, 'r', encoding='utf8' ) as nbfile:\n",
    "            nb = json.load( nbfile )\n",
    "            code_cells = []\n",
    "            for cell in nb['cells']:\n",
    "                if cell['cell_type'] != 'code':\n",
    "                    continue\n",
    "                cell_text = sub(r'#.*', '', ''.join(s for s in cell['source'] if not s.startswith('#')))\n",
    "                core_text = skip_functions(cell_text, ignored_function_names)\n",
    "                if core_text:\n",
    "                    all_solutions[learner.lastname] = core_text\n",
    "\n",
    "    no_duplicates = True\n",
    "\n",
    "    print('Processing…', end='')\n",
    "    similarPairs = checkNCD(all_solutions, threshold)\n",
    "    print('done!')\n",
    "\n",
    "    if len(similarPairs) > 0:\n",
    "        formatted_output = sorted(\n",
    "            (similarPairs[pair], '{2}: ({0}, {1})'.format(pair[0], pair[1], round(similarPairs[pair], 2))) \n",
    "            for pair in similarPairs\n",
    "        )\n",
    "        print('Similar code in {}:'.format(notebook_name))\n",
    "        print('\\n'.join(x[1] for x in formatted_output))\n",
    "    else:\n",
    "        print('No duplicates')\n",
    "    return all_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing…done!\n",
      "Similar definitions of “basic_local_search” in coding-hometask-2-1.ipynb:\n",
      "0.26: (Муравьев, Троцюк)\n",
      "0.44: (Марков, Проскурин)\n",
      "0.44: (Гришутин, Ремизова)\n",
      "0.46: (Мартинсон, Петров)\n",
      "0.48: (Гришутин, Мартинсон)\n",
      "0.48: (Гришутин, Петров)\n",
      "0.5: (Лернер, Рейдман)\n",
      "0.5: (Мартинсон, Ремизова)\n",
      "Processing…done!\n",
      "Similar definitions of “variable_depth_local_search” in coding-hometask-2-2.ipynb:\n",
      "0.06: (Горелик, Рязановский)\n",
      "0.34: (Куприянов, Лернер)\n",
      "0.35: (Горелик, Мурзин)\n",
      "0.35: (Мурзин, Рязановский)\n",
      "0.36: (Куприянов, Марков)\n",
      "0.38: (Марков, Лернер)\n",
      "0.4: (Куприянов, Ткаченко)\n",
      "0.41: (Куприянов, Мартинсон)\n",
      "0.41: (Лернер, Ткаченко)\n",
      "0.43: (Мартинсон, Лернер)\n",
      "0.45: (Марков, Мартинсон)\n",
      "0.45: (Марков, Ткаченко)\n",
      "0.47: (Горелик, Мартинсон)\n",
      "0.47: (Мартинсон, Ткаченко)\n",
      "0.48: (Мартинсон, Рязановский)\n",
      "0.49: (Горелик, Куприянов)\n",
      "0.49: (Куприянов, Рязановский)\n",
      "0.49: (Горелик, Лернер)\n",
      "0.49: (Лернер, Рязановский)\n",
      "Processing…done!\n",
      "Similar definitions of “solve_tsp_nearest_neighbour” in coding-hometask-3-1.ipynb:\n",
      "0.27: (Мартинсон, Муравьев)\n",
      "0.35: (Гришутин, Марков)\n",
      "0.37: (Зуева, Марков)\n",
      "0.4: (Белых, Калиниченко)\n",
      "0.4: (Белых, Муравьев)\n",
      "0.4: (Калиниченко, Мартинсон)\n",
      "0.42: (Калиниченко, Муравьев)\n",
      "0.42: (Марков, Петров)\n",
      "0.42: (Гришутин, Куприянов)\n",
      "0.43: (Белых, Мартинсон)\n",
      "0.44: (Муравьев, Петров)\n",
      "0.44: (Гришутин, Зуева)\n",
      "0.44: (Гришутин, Петров)\n",
      "0.44: (Белых, Проскурин)\n",
      "0.44: (Петров, Ремизова)\n",
      "0.45: (Муравьев, Проскурин)\n",
      "0.45: (Зуева, Куприянов)\n",
      "0.46: (Калиниченко, Проскурин)\n",
      "0.47: (Белых, Петров)\n",
      "0.47: (Куприянов, Марков)\n",
      "0.48: (Куприянов, Рязановский)\n",
      "0.48: (Мартинсон, Петров)\n",
      "0.48: (Мартинсон, Проскурин)\n",
      "0.48: (Куприянов, Петров)\n",
      "0.48: (Петров, Ткаченко)\n",
      "0.48: (Гришутин, Муравьев)\n",
      "0.49: (Мартинсон, Ремизова)\n",
      "0.49: (Петров, Проскурин)\n",
      "0.49: (Проскурин, Ткаченко)\n",
      "0.49: (Гришутин, Мартинсон)\n",
      "0.5: (Белых, Гришутин)\n",
      "0.5: (Белых, Ремизова)\n",
      "0.5: (Зуева, Петров)\n",
      "0.5: (Марков, Ткаченко)\n",
      "0.5: (Муравьев, Ремизова)\n",
      "0.5: (Муравьев, Ткаченко)\n",
      "0.5: (Ремизова, Ткаченко)\n",
      "Processing…done!\n",
      "Similar definitions of “solve_tsp_nearest_insertion” in coding-hometask-3-1.ipynb:\n",
      "0.33: (Мартинсон, Муравьев)\n",
      "0.35: (Горелик, Мурзин)\n",
      "0.41: (Куприянов, Рязановский)\n",
      "0.46: (Марков, Ткаченко)\n",
      "0.49: (Гришутин, Муравьев)\n",
      "0.49: (Куприянов, Якушева)\n",
      "0.49: (Рязановский, Якушева)\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting ':' delimiter: line 26 column 9 (char 1325)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-5fa499b4089a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# checkoutToDate(datetime(2017,5,8,23,59,59))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0msolutions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_plagiarism_in_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'coding-hometask-4-1.ipynb'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'solve_tsp_with_lp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# checkoutToDate(datetime(2017,5,24,23,59,59))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-db840b39adb0>\u001b[0m in \u001b[0;36mfind_plagiarism_in_function\u001b[1;34m(notebook_name, function_name, threshold)\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf8'\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnbfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mnb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mnbfile\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0mcode_cells\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcell\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cells'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[0mcls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m         parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 354\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m         \"\"\"\n\u001b[1;32m--> 339\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m         \"\"\"\n\u001b[0;32m    354\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting ':' delimiter: line 26 column 9 (char 1325)"
     ]
    }
   ],
   "source": [
    "# checkoutToDate(datetime(2017,3,19,23,59,59))\n",
    "# solutions = find_plagiarism_in_function('coding-hometask-1.ipynb', 'solve_bp_search')\n",
    "\n",
    "# checkoutToDate(datetime(2017,3,27,23,59,59))\n",
    "solutions = find_plagiarism_in_function('coding-hometask-2-1.ipynb', 'basic_local_search')\n",
    "\n",
    "# checkoutToDate(datetime(2017,4,10,23,59,59))\n",
    "solutions = find_plagiarism_in_function('coding-hometask-2-2.ipynb', 'variable_depth_local_search')\n",
    "\n",
    "# checkoutToDate(datetime(2017,4,2,23,59,59))\n",
    "solutions = find_plagiarism_in_function('coding-hometask-3-1.ipynb', 'solve_tsp_nearest_neighbour')\n",
    "solutions = find_plagiarism_in_function('coding-hometask-3-1.ipynb', 'solve_tsp_nearest_insertion')\n",
    "\n",
    "# checkoutToDate(datetime(2017,4,17,23,59,59))\n",
    "# solutions = find_plagiarism_in_function('coding-hometask-3-2.ipynb', 'lower_bound_tsp')\n",
    "\n",
    "# checkoutToDate(datetime(2017,5,8,23,59,59))\n",
    "solutions = find_plagiarism_in_function('coding-hometask-4-1.ipynb', 'solve_tsp_with_lp')\n",
    "\n",
    "# checkoutToDate(datetime(2017,5,24,23,59,59))\n",
    "# solutions = find_plagiarism_in_function('coding-hometask-5-1.ipynb', 'choose_landmarks')\n",
    "# solutions = find_plagiarism_in_function('coding-hometask-5-1.ipynb', 'precalculate_landmark_distances')\n",
    "# solutions = find_plagiarism_in_function('coding-hometask-5-1.ipynb', 'a_star_with_landmarks')\n",
    "\n",
    "# checkoutToDate(datetime(2017,3,27,23,59,59))\n",
    "# solutions = find_plagiarism_in_code('coding-hometask-2-1.ipynb', ['read_col_file'])\n",
    "\n",
    "# checkoutToDate(datetime(2017,4,10,23,59,59))\n",
    "# solutions = find_plagiarism_in_code('coding-hometask-2-2.ipynb', ['read_instance', 'get_quality', 'run_all'])\n",
    "\n",
    "# checkoutToDate(datetime(2017,4,2,23,59,59))\n",
    "# solutions = find_plagiarism_in_code('coding-hometask-3-1.ipynb', ['read_tsp_instance', 'euclidean_distance', 'calculate_tour_length', 'run_all'])\n",
    "\n",
    "# checkoutToDate(datetime(2017,4,17,23,59,59))\n",
    "# solutions = find_plagiarism_in_code('coding-hometask-3-2.ipynb', ['read_tsp_instance', 'euclidean_distance', 'run_all'])\n",
    "\n",
    "# checkoutToDate(datetime(2017,5,8,23,59,59))\n",
    "# solutions = find_plagiarism_in_code('coding-hometask-4-1.ipynb', ['dist15'])\n",
    "\n",
    "# checkoutToDate(datetime(2017,5,24,23,59,59))\n",
    "# solutions = find_plagiarism_in_code('coding-hometask-5-1.ipynb', ['read_node_coords', 'read_arcs', 'run_all'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
